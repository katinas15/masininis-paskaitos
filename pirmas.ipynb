{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    (\"Vardas1\", 0, 165, 55),\n",
    "    (\"Vardas2\", 1, 183, 95),\n",
    "    (\"Vardas3\", 0, 171, 60),\n",
    "    (\"Vardas4\", 1, 194, 102),\n",
    "    (\"Vardas5\", 1, \"?\", 80),\n",
    "    (\"Vardas6\", 1, 185, 90),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidurkis 187.33333333333334\n",
      "Mediana  185.0\n"
     ]
    }
   ],
   "source": [
    "# pirmas\n",
    "df = pd.DataFrame(data, columns=['vardas', 'lytis', 'ugis', 'svoris'])\n",
    "filteredTable = df.drop(df[df['ugis'] == \"?\"].index)\n",
    "\n",
    "men = filteredTable[filteredTable['lytis'] == 1]\n",
    "print(f\"Vidurkis {men['ugis'].mean()}\")\n",
    "print(f\"Mediana  {men['ugis'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ugis euclidean - 183.04910652784145\n",
      "ugis manhattan - 183.81314372942035\n",
      "ugis Čebyšavo  - 182.59016394031966\n"
     ]
    }
   ],
   "source": [
    "#antra\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def norm(column):\n",
    "    return (column - np.mean(column))/np.std(column)\n",
    "\n",
    "def denorm(norm_var, column):\n",
    "    return norm_var * np.std(column) + np.mean(column)\n",
    "\n",
    "def metrikos_skaiciavimas(kintamieji, metrikos):\n",
    "    return (1/np.sum(1/metrikos)*np.sum(kintamieji/metrikos))\n",
    "\n",
    "norm_lytis = norm(df['lytis'])\n",
    "norm_ugis = norm(filteredTable['ugis'])\n",
    "norm_svoris = norm(df['svoris'])\n",
    "\n",
    "\n",
    "atstumas_e = np.sqrt((norm_lytis[4] - norm_lytis)**2+(norm_svoris[4]-norm_svoris)**2)\n",
    "del atstumas_e[4]\n",
    "\n",
    "ugis_norm_e = metrikos_skaiciavimas(norm_ugis, atstumas_e)\n",
    "ugis_e = denorm(ugis_norm_e, filteredTable['ugis'])\n",
    "print(f\"ugis euclidean - {ugis_e}\")\n",
    "\n",
    "\n",
    "\n",
    "atstumas_m = np.abs(norm_lytis[4] - norm_lytis)+np.abs(norm_svoris[4]-norm_svoris)\n",
    "del atstumas_m[4]\n",
    "\n",
    "\n",
    "ugis_norm_m = metrikos_skaiciavimas(norm_ugis, atstumas_m)\n",
    "ugis_m = denorm(ugis_norm_m, filteredTable['ugis'])\n",
    "print(f\"ugis manhattan - {ugis_m}\")\n",
    "\n",
    "atstumas_c = np.amax(\n",
    "                np.stack(\n",
    "                    (np.abs(norm_lytis[4] - norm_lytis), np.abs(norm_svoris[4] - norm_svoris)\n",
    "                ), axis=1), \n",
    "            axis=1).tolist()\n",
    "\n",
    "del atstumas_c[4]\n",
    "atstumas_c = pd.DataFrame(atstumas_c)[0]\n",
    "\n",
    "norm_ugis[4] = norm_ugis[5]\n",
    "del norm_ugis[5]\n",
    "\n",
    "ugis_norm_c = metrikos_skaiciavimas(norm_ugis, atstumas_c)\n",
    "ugis_c = denorm(ugis_norm_c, filteredTable['ugis'])\n",
    "print(f\"ugis Čebyšavo  - {ugis_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ugis Koreliacija - 179.58884652676338\n"
     ]
    }
   ],
   "source": [
    "#trecias\n",
    "filteredTable = filteredTable.astype({\"ugis\": np.int64})\n",
    "\n",
    "avg_lyt = filteredTable['lytis'].mean()\n",
    "avg_ugis = filteredTable['ugis'].mean()\n",
    "avg_svoris = filteredTable['svoris'].mean()\n",
    "# print(f\"average lyt {avg_lyt}\")\n",
    "# print(f\"average ugis {avg_ugis}\")\n",
    "# print(f\"average svoris {avg_svoris}\")\n",
    "\n",
    "corr = filteredTable.corr()\n",
    "# print(corr)\n",
    "corr_lyt = corr['ugis'][0]\n",
    "corr_svoris = corr['ugis'][2]\n",
    "atkurimas_svoris = corr_svoris * (df['svoris'][4] - avg_svoris)\n",
    "atkurimas_lyt = corr_lyt * (df['lytis'][4] - avg_lyt)\n",
    "atsakymas = avg_ugis + (1/(abs(corr_lyt) + abs(corr_svoris)) * (atkurimas_svoris + atkurimas_lyt)) \n",
    "# print(atsakymas)\n",
    "print(f\"ugis Koreliacija - {atsakymas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  3  4  5  6  7\n",
      "0  1  1  1  0  0  0  1\n",
      "1  0  1  0  0  1  0  0\n",
      "2  0  0  0  1  0  1  1\n",
      "3  0  0  1  0  0  0  0\n",
      "4  0  1  0  1  0  0  0\n",
      "5  1  0  0  0  1  1  0\n"
     ]
    }
   ],
   "source": [
    "rekomendacijosRaw = [\n",
    "    (\"A. Klasikinė suknelė\",                1, 1, 1, 0, 0, 0, 1),\n",
    "    (\"B. Retro suknelė\",                    0, 1, 0, 0, 1, 0, 0),\n",
    "    (\"C. Klasikinis kostiumas su kelnėmis\", 0, 0, 0, 1, 0, 1, 1),\n",
    "    (\"D. Klasikinis kostiumas su sijonu\",   0, 0, 1, 0, 0, 0, 0),\n",
    "    (\"E. Kelnės\",                           0, 1, 0, 1, 0, 0, 0),\n",
    "    (\"F. Sijonas\",                          1, 0, 0, 0, 1, 1, 0)\n",
    "]\n",
    "\n",
    "rekomendacijosFull = pd.DataFrame(rekomendacijosRaw, \\\n",
    "    columns=['prekes', '1', '2', '3', '4', '5', '6', '7'])\n",
    "rekomendacijos = rekomendacijosFull.drop(\"prekes\", axis=1)\n",
    "print(rekomendacijos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         2.         2.23606798 1.73205081 2.         2.23606798]\n",
      " [2.         0.         2.23606798 1.73205081 1.41421356 1.73205081]\n",
      " [2.23606798 2.23606798 0.         2.         1.73205081 2.        ]\n",
      " [1.73205081 1.73205081 2.         0.         1.73205081 2.        ]\n",
      " [2.         1.41421356 1.73205081 1.73205081 0.         2.23606798]\n",
      " [2.23606798 1.73205081 2.         2.         2.23606798 0.        ]]\n",
      "prekes\n",
      "D. Klasikinis kostiumas su sijonu    0\n",
      "E. Kelnės                            1\n",
      "Name: atstumas, dtype: int64\n",
      "                              prekes  atstumas\n",
      "0  D. Klasikinis kostiumas su sijonu  1.732051\n",
      "1                          E. Kelnės  1.732051\n"
     ]
    }
   ],
   "source": [
    "#ketvirtas\n",
    "from scipy.spatial.distance import cdist\n",
    "dist = cdist(rekomendacijos, rekomendacijos, 'euclid')\n",
    "print(dist)\n",
    "for i in range(len(dist)):\n",
    "    dist[i][i] = np.inf\n",
    "\n",
    "shortest_dist = []\n",
    "for index, preke in enumerate(rekomendacijos[\"7\"]):\n",
    "    if preke == 1:\n",
    "        shortest_dist_in_row_index = dist[index].argmin()\n",
    "        shortest_dist_in_row = dist[index].min()\n",
    "        row_name = rekomendacijosFull[\"prekes\"][shortest_dist_in_row_index]\n",
    "        shortest_dist.append((row_name, shortest_dist_in_row))\n",
    "\n",
    "shortest_dist = pd.DataFrame(shortest_dist, columns=['prekes', 'atstumas'])\n",
    "\n",
    "# https://stackoverflow.com/a/59343150/9816439\n",
    "shortest_dist = shortest_dist.loc[shortest_dist.groupby('prekes').atstumas.idxmin()]\n",
    "print(shortest_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penkta\n",
    "filmaiRaw = [\n",
    "    (\"Vardas1\", 2, 5, 1, 5, 5, 3, 2),\n",
    "    (\"Vardas2\", 2, 4, 1, 4, 4, 4, 3),\n",
    "    (\"Vardas3\", 1, 3, 2, 3, 5, 3, 4),\n",
    "    (\"Vardas4\", 3, 5, 1, 5, 5, 4, 5),\n",
    "    (\"Vardas5\", 3, 5, 2, 3, 5, 3, 3),\n",
    "    (\"Vardas6\", 2, 5, 1, 5, None, None, 2)\n",
    "]\n",
    "\n",
    "filmaiFull = pd.DataFrame(filmaiRaw, \\\n",
    "     columns=['naudotojas', 'siaubo', 'veiksmo',\\\n",
    "          'drama', 'nuotykiu', 'scifi', 'mitologija', 'istorinis'])\n",
    "filmai = filmaiFull.drop(\"naudotojas\", axis=1)\n",
    "\n",
    "corr = filmai.corr()\n",
    "vid = filmai.mean()\n",
    "user_values = filmai.iloc[5]\n",
    "\n",
    "scifi_corr = corr.scifi\n",
    "atsakymas_scifi = vid.scifi + \\\n",
    "    (1/(sum(abs(scifi_corr.values)))) * \\\n",
    "    (\n",
    "        scifi_corr[0] * (user_values[0] - vid[0]) + \\\n",
    "        scifi_corr[1] * (user_values[1] - vid[1]) + \\\n",
    "        scifi_corr[2] * (user_values[2] - vid[2]) + \\\n",
    "        scifi_corr[3] * (user_values[3] - vid[3]) + \\\n",
    "        scifi_corr[6] * (user_values[6] - vid[6])\n",
    "    )\n",
    "\n",
    "print(f\"scifi -      {atsakymas_scifi}\")\n",
    "\n",
    "mito_corr = corr.mitologija\n",
    "atsakymas_mito = vid.mitologija + \\\n",
    "    (1/(sum(abs(mito_corr.values)))) * \\\n",
    "    (\n",
    "        mito_corr[0] * (user_values[0] - vid[0]) + \\\n",
    "        mito_corr[1] * (user_values[1] - vid[1]) + \\\n",
    "        mito_corr[2] * (user_values[2] - vid[2]) + \\\n",
    "        mito_corr[3] * (user_values[3] - vid[3]) + \\\n",
    "        mito_corr[6] * (user_values[6] - vid[6])\n",
    "    )\n",
    "\n",
    "print(f\"mitologija - {atsakymas_mito}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "30\n",
      "[15 15 16 16 17 17 18 18]\n",
      "----\n",
      "15\n",
      "15\n",
      "18\n",
      "18\n",
      "[16 16 17 17]\n",
      "----\n",
      "[16 16 17 17]\n",
      "liko: \n",
      "[16 16 17 17]\n"
     ]
    }
   ],
   "source": [
    "#sesta\n",
    "from scipy import special\n",
    "\n",
    "def erfc_value(array, value):\n",
    "    return abs(value - array.mean())/array.std()\n",
    "\n",
    "def anomaly_criteria(array):\n",
    "    return 1/(2 * len(array))\n",
    "\n",
    "A = np.asarray([15, 17, 16, 16, 18, 17, 15, 30, 18])\n",
    "A = np.sort(A)\n",
    "\n",
    "anomalies = True\n",
    "dataset = A\n",
    "while anomalies:\n",
    "    anomalies = False\n",
    "    indexes = []\n",
    "    print('----')\n",
    "    for index, i in enumerate(dataset):\n",
    "        if special.erfc(erfc_value(dataset, i)) < anomaly_criteria(dataset):\n",
    "            indexes.append(index)\n",
    "            print(i)\n",
    "            anomalies = True\n",
    "    \n",
    "    newDataset = []\n",
    "    for index, i in enumerate(dataset):\n",
    "        if not index in indexes:\n",
    "            newDataset.append(i)\n",
    "    dataset = np.array(newDataset)\n",
    "    print(dataset)\n",
    "\n",
    " \n",
    "\n",
    "print('liko: ')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isimtys: \n",
      "30\n",
      "liko: \n",
      "[15 15 16 16 17 17 18 18]\n"
     ]
    }
   ],
   "source": [
    "A = np.asarray([15, 17, 16, 16, 18, 17, 15, 30, 18])\n",
    "A = np.sort(A)\n",
    "q25 = np.quantile(A, 0.25)\n",
    "q75 = np.quantile(A, 0.75)\n",
    "# print(q25, q75)\n",
    "condition1 = q25 - 1.5 * (q75 - q25)\n",
    "condition2 = q75 + 1.5 * (q75 - q25)\n",
    "# print(condition1, condition2)\n",
    "\n",
    "print('isimtys: ')\n",
    "anomalies = True\n",
    "dataset = A\n",
    "while anomalies:\n",
    "    anomalies = False\n",
    "    for index, i in enumerate(dataset):\n",
    "        q25 = np.quantile(dataset, 0.25)\n",
    "        q75 = np.quantile(dataset, 0.75)\n",
    "        # print(q25, q75)\n",
    "\n",
    "        condition1 = q25 - 1.5 * (q75 - q25)\n",
    "        condition2 = q75 + 1.5 * (q75 - q25)\n",
    "        # print(condition1, condition2)\n",
    "        if i < condition1 or i > condition2:\n",
    "            dataset = np.delete(dataset, index)\n",
    "            print(i)\n",
    "            anomalies = True\n",
    "\n",
    "\n",
    "print('liko: ')\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0eed9422d3b6c012327c82824da2c3cc1115dadb006bfd9a899d8ed44f220fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
